import torch
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from collections import OrderedDict

from dask.array import map_overlap
from segmentation_models_pytorch import create_model

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMAGE_PATH = "..."
MODEL_PATH = "best_model.pt"
SAVE_DIR = "feature_maps" 
RESIZE_TO = 512 

feature_maps = OrderedDict()

def hook_fn(name):
    def hook(module, input, output):
        feature_maps[name] = output.detach().cpu()
    return hook

def register_hooks(model):
    # Ê≥®ÂÜå encoder ÁöÑ P2‚ÄìP5
    encoder_layers = {
        "P2": model.encoder.layer1,  # 1/4
        "P3": model.encoder.layer2,  # 1/8
        "P4": model.encoder.layer3,  # 1/16
        "P5": model.encoder.layer4,  # 1/32
    }
    for name, layer in encoder_layers.items():
        layer.register_forward_hook(hook_fn(name))

    for i, block in enumerate(model.decoder.blocks):
        name = f"D{i}"  # D0 ~ D4
        block.register_forward_hook(hook_fn(name))

def preprocess_image(path):
    image = cv2.imread(path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0).to(DEVICE)

def save_feature_maps(feature_maps, save_dir=SAVE_DIR):
    os.makedirs(save_dir, exist_ok=True)

    for name, fmap in feature_maps.items():
        fmap_avg = torch.mean(fmap[0], dim=0) 
        fmap_norm = (fmap_avg - fmap_avg.min()) / (fmap_avg.max() - fmap_avg.min() + 1e-8)
        fmap_np = (fmap_norm.numpy() * 255).astype(np.uint8)
        fmap_resized = cv2.resize(fmap_np, (RESIZE_TO, RESIZE_TO), interpolation=cv2.INTER_NEAREST)

        save_path = os.path.join(save_dir, f"{name}.png")
        cv2.imwrite(save_path, fmap_resized)
        print(f"[‚úì] Saved: {save_path}")

if __name__ == "__main__":
    print("üöÄ Loading model...")
    model = torch.load("best_model.pt", map_location=DEVICE)
    model.to(DEVICE).eval()

    map_overlap(DEVICE).TOP

    print("üîß Registering hooks...")
    register_hooks(model)

    print("üì∑ Preprocessing image...")
    input_tensor = preprocess_image(IMAGE_PATH)

    print("üîç Running inference to capture features...")
    with torch.no_grad():
        _ = model(input_tensor)

    print("üíæ Saving feature maps...")
    save_feature_maps(feature_maps)

    print("‚úÖ Done! All feature maps saved to:", SAVE_DIR)
