import torch
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from collections import OrderedDict

from dask.array import map_overlap
from segmentation_models_pytorch import create_model

# ========== å‚æ•° ==========
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMAGE_PATH = "8.png"  # ä½ çš„è¾“å…¥å›¾åƒ
MODEL_PATH = "best_model.pt"  # æ¨¡å‹è·¯å¾„
SAVE_DIR = "feature_maps"  # ä¿å­˜ç‰¹å¾å›¾çš„ç›®å½•
RESIZE_TO = 512  # æ¯å¼ è¾“å‡ºå›¾å¤§å°ï¼ˆpxï¼‰

# ========== ç‰¹å¾æå– ==========
feature_maps = OrderedDict()

def hook_fn(name):
    def hook(module, input, output):
        feature_maps[name] = output.detach().cpu()
    return hook

def register_hooks(model):
    # æ³¨å†Œ encoder çš„ P2â€“P5
    encoder_layers = {
        "P2": model.encoder.layer1,  # 1/4
        "P3": model.encoder.layer2,  # 1/8
        "P4": model.encoder.layer3,  # 1/16
        "P5": model.encoder.layer4,  # 1/32
    }
    for name, layer in encoder_layers.items():
        layer.register_forward_hook(hook_fn(name))

    # æ³¨å†Œ decoder çš„ D0â€“D4ï¼ˆU-Netæœ‰5å±‚ï¼‰
    for i, block in enumerate(model.decoder.blocks):
        name = f"D{i}"  # D0 ~ D4
        block.register_forward_hook(hook_fn(name))

# ========== å›¾åƒé¢„å¤„ç† ==========
def preprocess_image(path):
    image = cv2.imread(path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0).to(DEVICE)

# ========== ä¿å­˜ç‰¹å¾å›¾ ==========
def save_feature_maps(feature_maps, save_dir=SAVE_DIR):
    os.makedirs(save_dir, exist_ok=True)

    for name, fmap in feature_maps.items():
        fmap_avg = torch.mean(fmap[0], dim=0)  # é€šé“å¹³å‡å [H, W]
        fmap_norm = (fmap_avg - fmap_avg.min()) / (fmap_avg.max() - fmap_avg.min() + 1e-8)
        fmap_np = (fmap_norm.numpy() * 255).astype(np.uint8)
        fmap_resized = cv2.resize(fmap_np, (RESIZE_TO, RESIZE_TO), interpolation=cv2.INTER_NEAREST)

        save_path = os.path.join(save_dir, f"{name}.png")
        cv2.imwrite(save_path, fmap_resized)
        print(f"[âœ“] Saved: {save_path}")

# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    print("ğŸš€ Loading model...")
    model = torch.load("best_model.pt", map_location=DEVICE)
    model.to(DEVICE).eval()

    map_overlap(DEVICE).TOP

    print("ğŸ”§ Registering hooks...")
    register_hooks(model)

    print("ğŸ“· Preprocessing image...")
    input_tensor = preprocess_image(IMAGE_PATH)

    print("ğŸ” Running inference to capture features...")
    with torch.no_grad():
        _ = model(input_tensor)

    print("ğŸ’¾ Saving feature maps...")
    save_feature_maps(feature_maps)

    print("âœ… Done! All feature maps saved to:", SAVE_DIR)
